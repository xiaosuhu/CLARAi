{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6155, 2.6641])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = pd.read_csv('./data.csv')\n",
    "label_seq = pd.read_csv('label.csv')\n",
    "\n",
    "train_labels_flat = label_seq.values.flatten()\n",
    "train_labels_flat\n",
    "\n",
    "# Compute class weights (inverse of class frequencies)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels_flat), y=train_labels_flat)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 36, 256)\n",
      "(100, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "sequence_length = 256  # Length of each subsequence\n",
    "num_subsequences = 100  # Number of subsequences to extract = 100 samples\n",
    "\n",
    "# Get possible starting indices, ensuring there's enough space for a full subsequence\n",
    "possible_starts = np.arange(0, len(sequence) - sequence_length + 1)\n",
    "np.random.shuffle(possible_starts)\n",
    "\n",
    "# Select the first `num_subsequences` starting indices\n",
    "selected_starts = possible_starts[:num_subsequences]\n",
    "\n",
    "# Create a list to hold the subsequences\n",
    "subsequences = [sequence.iloc[start:start + sequence_length].values for start in selected_starts]\n",
    "sublabels = [label_seq.iloc[start:start + sequence_length].values for start in selected_starts]\n",
    "\n",
    "# Convert subsequences list to a NumPy array\n",
    "subsequences_array = np.array(subsequences)\n",
    "sublabels_array = np.array(sublabels)\n",
    "\n",
    "# Reshape subsequences_array to (num_subsequences, num_channels, sequence_length)\n",
    "subsequences_array = subsequences_array.transpose(0, 2, 1)  # From (100, 256, 36) to (100, 36, 256)\n",
    "\n",
    "# Reshape sublabels_array to (num_subsequences, 1, sequence_length)\n",
    "sublabels_array = sublabels_array.transpose(0, 2, 1)  # From (100, 256, 1) to (100, 1, 256)\n",
    "\n",
    "# subsequences_array will have shape (num_subsequences, sequence_length, num_channels)\n",
    "print(subsequences_array.shape)  # Should print (100, 100, 36)\n",
    "print(sublabels_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class ResNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes=1):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        # Use resnet18 but replace the first layer with Conv1d\n",
    "        self.resnet = resnet18(pretrained=False)\n",
    "        self.resnet.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes=1):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        \n",
    "        # Load the ResNet-18 architecture\n",
    "        self.resnet = resnet18(pretrained=False)\n",
    "        \n",
    "        # Modify the first layer to work with 1D convolutions\n",
    "        self.resnet.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Replace 2D BatchNorm and Pooling layers with 1D equivalents\n",
    "        self.resnet.bn1 = nn.BatchNorm1d(64)\n",
    "        self.resnet.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Modify the fully connected layer to match the number of output classes\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\"\"\"\n",
    "\n",
    "# Define a Residual Block for 1D Convolution with stride=1\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define ResNet-18 using 1D convolutions without downsampling\n",
    "class ResNet1D(nn.Module):\n",
    "    def __init__(self, block, layers, in_channels=36, num_classes=1):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # Initial layers\n",
    "        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=7, stride=1, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Remove max pooling to preserve time dimension\n",
    "        # self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet Layers\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3])\n",
    "\n",
    "        # Final layer\n",
    "        self.conv_out = nn.Conv1d(512, num_classes, kernel_size=1)\n",
    "\n",
    "        # Ensure output time dimension is preserved\n",
    "        self.upsample = nn.Upsample(size=256, mode='linear', align_corners=False)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.conv_out(x)\n",
    "\n",
    "        # Apply upsampling to ensure the output time dimension is 256\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Example of instantiating the model with 36 input channels (your time series data)\n",
    "\n",
    "# ResNet-18 specific configuration\n",
    "model = ResNet1D(BasicBlock1D, [2, 2, 2, 2], in_channels=36, num_classes=1).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))  # Output 1 for binary classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet1D(\n",
       "  (conv1): Conv1d(36, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock1D(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock1D(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock1D(\n",
       "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock1D(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock1D(\n",
       "      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock1D(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock1D(\n",
       "      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock1D(\n",
       "      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_out): Conv1d(512, 1, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([80, 1, 256]), torch.Size([80, 36, 256]), torch.Size([80, 1, 256]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_data).shape, train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "class NeuroimagingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "    \n",
    "neuroimaging_data = subsequences_array\n",
    "labels = sublabels_array\n",
    "\n",
    "input_size = neuroimaging_data.shape[2]  # Number of features (channels)\n",
    "\n",
    "# Preprocessing (e.g., normalization)\n",
    "scaler = StandardScaler()\n",
    "neuroimaging_data = scaler.fit_transform(neuroimaging_data.reshape(-1, input_size)).reshape(neuroimaging_data.shape)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(neuroimaging_data, labels, test_size=0.2, random_state=42)\n",
    "train_data, test_data = torch.tensor(train_data, dtype=torch.float32).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")), torch.tensor(test_data, dtype=torch.float32).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "train_labels, test_labels = torch.tensor(train_labels, dtype=torch.float32).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")), torch.tensor(test_labels, dtype=torch.float32).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = NeuroimagingDataset(train_data, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross-Entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaos\\AppData\\Local\\Temp\\ipykernel_16884\\1166643298.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9839934825897216\n",
      "Epoch 2, Loss: 0.20158927142620087\n",
      "Epoch 3, Loss: 0.05556968897581101\n",
      "Epoch 4, Loss: 0.015971654653549196\n",
      "Epoch 5, Loss: 0.009441157430410385\n",
      "Epoch 6, Loss: 0.004571363562718034\n",
      "Epoch 7, Loss: 0.0025194106390699746\n",
      "Epoch 8, Loss: 0.0017326485132798553\n",
      "Epoch 9, Loss: 0.0010830884915776552\n",
      "Epoch 10, Loss: 0.000905243307352066\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            outputs = model(data)\n",
    "            preds = (outputs > 0.5).float()  # Convert probabilities to binary predictions\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Flatten the lists to compare predictions and labels\n",
    "    all_labels = np.concatenate(all_labels, axis=0).flatten()\n",
    "    all_preds = np.concatenate(all_preds, axis=0).flatten()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaos\\AppData\\Local\\Temp\\ipykernel_16884\\1166643298.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999\n",
      "Confusion Matrix:\n",
      "[[16232     2]\n",
      " [    0  4246]]\n"
     ]
    }
   ],
   "source": [
    "acc, cm = evaluate(model, train_loader)\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchwin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
